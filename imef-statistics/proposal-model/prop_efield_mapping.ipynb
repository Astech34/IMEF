{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import xarray as xr\n",
    "\n",
    "# my imports\n",
    "import prop_data_prep as pdp\n",
    "import prop_nn_models as pnn\n",
    "import prop_nn_functions as pnf\n",
    "import prop_MCDO_functions as MCDO\n",
    "import prop_visualizations as viz\n",
    "from prop_mms_data_prep import write_toDf, sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "# inputs t0, te, imef_data\n",
    "# assume nans removed\n",
    "\n",
    "# load model\n",
    "model_floc = \"prop_models/\"  # directory to save model\n",
    "model_fname = \"ANN_complete_EXYZ\"  # sample model\n",
    "model_path = model_floc + model_fname  # full model path\n",
    "\n",
    "# load train/test dataset (want to use test data in futr maybe?)\n",
    "imef_data = pd.read_pickle(\"prop_models/complete_training_df\")\n",
    "time_indx = imef_data.index.values[100:160]  # \"test times\"\n",
    "\n",
    "# load hyperparameter configuration\n",
    "f = open(model_path + \"_config.json\")\n",
    "CONFIG = json.load(f)\n",
    "\n",
    "# initialize the model\n",
    "model = pnn.FeedForwardNN_MCDO(\n",
    "    CONFIG[\"num_features\"],\n",
    "    CONFIG[\"seq_len\"],\n",
    "    CONFIG[\"hidden_size\"],\n",
    "    CONFIG[\"output_size\"],\n",
    "    CONFIG[\"dropout_prob\"],\n",
    ")\n",
    "model.load_state_dict(torch.load(model_floc + model_fname))\n",
    "\n",
    "predictors = [\n",
    "    \"OMNI_IMF\",\n",
    "    \"OMNI_Vx\",\n",
    "    \"OMNI_Vy\",\n",
    "    \"OMNI_Vz\",\n",
    "    \"OMNI_SYM_H\",\n",
    "    \"L\",\n",
    "    \"MLAT\",\n",
    "    \"MLT\",\n",
    "]  # predictors, features\n",
    "target = [\"EX\", \"EY\", \"EZ\"]\n",
    "\n",
    "# separate swolar wind (swi) and location (loc) predictors\n",
    "#   - this will be used to index and assemble matrix correctly\n",
    "swi_predictors = predictors[:5]  # solar wind predictors\n",
    "loc_predictors = predictors[5:]  # location (L,MLT, MLAT) predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE DEISGN MATRIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assemble Design Matrix\n",
    "for Izzak's code, see\n",
    "    - imef/efield/model_creation/NN_functions.py \n",
    "        - (get_NN_inputs function!)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "design_matrix = []  # list to hold desigh matrix\n",
    "time_matrix = []  # list to hold times assoc. with matrix values\n",
    "\n",
    "for ix in range(0, len(time_indx)):\n",
    "    ix_matrix_row = []  # matrix row at loop index (ix)\n",
    "\n",
    "    # get time intervals\n",
    "    # `- (!) should be end??\n",
    "    time_intervals = pd.date_range(end=time_indx[ix], freq=\"5T\", periods=60)\n",
    "    # print('index',time_indx)\n",
    "    # print('intrvl',time_intervals)\n",
    "    # try:\n",
    "    # write predictors at ix to row\n",
    "\n",
    "    # loop through each swind predictor and append it to matrix\n",
    "    for swi_var in swi_predictors:\n",
    "        # pull predictor from dataset as xarray\n",
    "        swi_xarr = imef_data[swi_var].to_xarray()\n",
    "\n",
    "        # split data in interval format and append to design matrix row\n",
    "        ix_arr = swi_xarr.sel(time=time_intervals, method=\"nearest\").values.tolist()\n",
    "        ix_matrix_row += ix_arr  \n",
    "\n",
    "    # get location data (L, MLT, MLAT) and assemble into matrix format\n",
    "    loc_data = np.array(\n",
    "        [\n",
    "            imef_data[\"L\"].values[ix],\n",
    "            np.cos(np.pi / 12 * imef_data[\"MLT\"].values[ix]),\n",
    "            np.sin(np.pi / 12 * imef_data[\"MLT\"].values[ix]),\n",
    "            np.cos(imef_data[\"MLAT\"].values[ix]),\n",
    "            np.sin(imef_data[\"MLAT\"].values[ix]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # write location data (np array) at ix to row (list)\n",
    "    ix_matrix_row += loc_data.tolist()\n",
    "\n",
    "    # append row to design matrix\n",
    "    # print(\"row\",ix_matrix_row)\n",
    "    design_matrix.append(ix_matrix_row)\n",
    "\n",
    "    # append times to time matrix\n",
    "    time_matrix.append(time_indx[ix])\n",
    "\n",
    "# torch tensor design matrix\n",
    "design_matrix_tensor = torch.tensor(design_matrix)\n",
    "\n",
    "# except Exception as ex:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[168, 480]' is invalid for input of size 51240",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_locations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv-imef/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv-imef/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/unh-srl/imef/imef-statistics/proposal-model/prop_nn_models.py:85\u001b[0m, in \u001b[0;36mFeedForwardNN_MCDO.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m#  When modeling time series with feed-forward NN's, it's important to note that there's a neuron\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# for each time step AND FEATURE; so if you have 60 time steps and 2 features, then you have 120 numbers\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# to give as input; so the NN see the time steps and features *at the same time*\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# we can express this idea by taking our 3d array (with original shape [num_pts, seq_len, num_feats])\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# and unfold into 2d (with new shape [num_pts, seq_len * num_feats])\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    out = self.fc1(x)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    out = self.relu(out)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    out = self.fc1(out)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    out = self.fc2(out)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[168, 480]' is invalid for input of size 51240"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for Izzak's code, see\n",
    "    - imef/data_manipulation.py\n",
    "    - visualizations/plot_nc_data.py\n",
    "    - imef/efield/model_creation/NN_functions.py\n",
    "    - imef/data/database.py\n",
    "        - **(predict_efield_and_potential function!)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "number_of_inputs = len(swi_predictors)  # number of inputs/predictors\n",
    "\n",
    "# unsure how to adjust this for all predicors? is this grabbing row or column?\n",
    "# izzak used:\n",
    "#   >> base_kp_values = design_matrix_tensor[-1].clone()\n",
    "# my variation (I don't know what to do for this):\n",
    "base_values = design_matrix_tensor[-1].clone()\n",
    "\n",
    "# izzak used:\n",
    "#   >> size_of_input_vector = 60 * number_of_inputs + 3\n",
    "# my variation:\n",
    "size_of_input_vector = 60 * number_of_inputs + 5\n",
    "\n",
    "# I THINK this is izzak's way of setting up the matrix to be accepted\n",
    "# by the model, but...its not clear.\n",
    "for L in range(4, 11):\n",
    "    for MLT in range(0, 24):\n",
    "        new_row = base_values.clone()\n",
    "        new_row[-3] = L\n",
    "        new_row[-2] = np.cos(np.pi / 12 * MLT)\n",
    "        new_row[-1] = np.sin(np.pi / 12 * MLT)\n",
    "        even_newer_row = torch.empty((1, size_of_input_vector))\n",
    "        even_newer_row[0] = new_row\n",
    "        if L == 4 and MLT == 0:\n",
    "            all_locations = even_newer_row\n",
    "        else:\n",
    "            all_locations = torch.cat((all_locations, even_newer_row))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(all_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_values \u001b[38;5;241m=\u001b[39m design_matrix_tensor[\u001b[43mdesign_matrix_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "base_values = design_matrix_tensor[design_matrix_tensor.columns[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-imef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
