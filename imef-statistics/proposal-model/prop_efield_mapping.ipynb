{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import xarray as xr\n",
    "\n",
    "# my imports\n",
    "import prop_data_prep as pdp\n",
    "import prop_nn_models as pnn\n",
    "import prop_nn_functions as pnf\n",
    "import prop_MCDO_functions as MCDO\n",
    "import prop_visualizations as viz\n",
    "from prop_mms_data_prep import write_toDf, sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "# inputs t0, te, imef_data\n",
    "# assume nans removed\n",
    "\n",
    "# load model\n",
    "model_floc = \"prop_models/\"  # directory to save model\n",
    "model_fname = \"ANN_complete_EXYZ\"  # sample model\n",
    "model_path = model_floc + model_fname  # full model path\n",
    "\n",
    "# load train/test dataset (want to use test data in futr maybe?)\n",
    "imef_data = pd.read_pickle(\"prop_models/complete_training_df\")\n",
    "time_indx = imef_data.index.values[100:160]  # \"test times\"\n",
    "\n",
    "# load hyperparameter configuration\n",
    "f = open(model_path + \"_config.json\")\n",
    "CONFIG = json.load(f)\n",
    "\n",
    "# initialize the model\n",
    "model = pnn.FeedForwardNN_MCDO(\n",
    "    CONFIG[\"num_features\"],\n",
    "    CONFIG[\"seq_len\"],\n",
    "    CONFIG[\"hidden_size\"],\n",
    "    CONFIG[\"output_size\"],\n",
    "    CONFIG[\"dropout_prob\"],\n",
    ")\n",
    "model.load_state_dict(torch.load(model_floc + model_fname))\n",
    "\n",
    "predictors = [\n",
    "    \"OMNI_IMF\",\n",
    "    \"OMNI_Vx\",\n",
    "    \"OMNI_Vy\",\n",
    "    \"OMNI_Vz\",\n",
    "    \"OMNI_SYM_H\",\n",
    "    \"L\",\n",
    "    \"MLAT\",\n",
    "    \"MLT\",\n",
    "]  # predictors, features\n",
    "target = [\"EX\", \"EY\", \"EZ\"]\n",
    "\n",
    "# separate swolar wind (swi) and location (loc) predictors\n",
    "#   - this will be used to index and assemble matrix correctly\n",
    "swi_predictors = predictors[:5]  # solar wind predictors\n",
    "loc_predictors = predictors[5:]  # location (L,MLT, MLAT) predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE DESIGN MATRIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.796475937539341\n",
      "9.78054494084098\n",
      "9.764557008063449\n",
      "10.27472622865742\n",
      "10.29713068705834\n",
      "10.319457497428042\n",
      "9.7753878239563\n",
      "9.759309599513628\n",
      "9.743174034259292\n",
      "9.79937551291163\n",
      "9.783319725201748\n",
      "9.76720715280763\n",
      "9.751037526772269\n",
      "9.73616676957596\n",
      "9.718525774767068\n",
      "10.292827977536419\n",
      "9.791609421117965\n",
      "9.775463218137455\n",
      "9.759260171674233\n",
      "9.742999939036828\n",
      "9.799770690433972\n",
      "9.734707446727823\n",
      "9.71829843136164\n",
      "9.807464615126909\n",
      "10.341517636849003\n",
      "10.364529131400724\n",
      "10.38746396148276\n",
      "9.781942922505943\n",
      "9.76557490424617\n",
      "9.749150009467561\n",
      "9.732667940299722\n",
      "11.078089685599195\n",
      "11.065803657779151\n",
      "11.053481071304583\n",
      "11.04112178781822\n",
      "11.028725636005499\n",
      "11.098394122111005\n",
      "11.085994572174902\n",
      "11.073558703391688\n",
      "11.061086309586912\n",
      "11.048577282312962\n",
      "11.03603143423023\n",
      "14.078295465085406\n",
      "14.07629057381014\n",
      "14.074246129741516\n",
      "14.070039298273104\n",
      "14.05166510761242\n",
      "14.046691768028966\n",
      "14.036298892197422\n",
      "12.973779460455619\n",
      "12.59035732319598\n",
      "14.094489169029833\n",
      "12.968763470907271\n",
      "11.960134777569609\n",
      "11.651651922784751\n",
      "11.57090672554885\n",
      "11.524084726242329\n",
      "11.512300572315828\n",
      "11.476757412246407\n",
      "11.380555499803878\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Assemble Design Matrix\n",
    "for Izzak's code, see\n",
    "    - imef/efield/model_creation/NN_functions.py \n",
    "        - (get_NN_inputs function!)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "design_matrix = []  # list to hold desigh matrix\n",
    "time_matrix = []  # list to hold times assoc. with matrix values\n",
    "\n",
    "for ix in range(0, len(time_indx)):\n",
    "    ix_matrix_row = []  # matrix row at loop index (ix)\n",
    "\n",
    "    # get time intervals\n",
    "    # `- (!) should be end??\n",
    "    time_intervals = pd.date_range(end=time_indx[ix], freq=\"5T\", periods=60) # maybe min scales?\n",
    "    # print('index',time_indx)\n",
    "    # print('intrvl',time_intervals)\n",
    "    # try:\n",
    "    # write predictors at ix to row\n",
    "\n",
    "    # loop through each swind predictor and append it to matrix\n",
    "    for swi_var in swi_predictors:\n",
    "        # pull predictor from dataset as xarray\n",
    "        swi_xarr = imef_data[swi_var].to_xarray()\n",
    "\n",
    "        # split data in interval format and append to design matrix row\n",
    "        ix_arr = swi_xarr.sel(time=time_intervals, method=\"nearest\").values.tolist()\n",
    "        ix_matrix_row += ix_arr  \n",
    "\n",
    "    # get location data (L, MLT, MLAT) and assemble into matrix format\n",
    "    loc_data = np.array(\n",
    "        [\n",
    "            imef_data[\"L\"].values[ix],\n",
    "            np.cos(np.pi / 12 * imef_data[\"MLT\"].values[ix]),\n",
    "            np.sin(np.pi / 12 * imef_data[\"MLT\"].values[ix]),\n",
    "            np.cos(imef_data[\"MLAT\"].values[ix]),\n",
    "            np.sin(imef_data[\"MLAT\"].values[ix]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(imef_data[\"L\"].values[ix])\n",
    "\n",
    "    # write location data (np array) at ix to row (list)\n",
    "    ix_matrix_row += loc_data.tolist()\n",
    "\n",
    "    # append row to design matrix\n",
    "    # print(\"row\",ix_matrix_row)\n",
    "    design_matrix.append(ix_matrix_row)\n",
    "\n",
    "    # append times to time matrix\n",
    "    time_matrix.append(time_indx[ix])\n",
    "\n",
    "# torch tensor design matrix\n",
    "design_matrix_tensor = torch.tensor(design_matrix)\n",
    "\n",
    "# np array design matrix \n",
    "design_matrix_arr = np.array(design_matrix)\n",
    "\n",
    "# except Exception as ex:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nL = 10 # number of bins for L\n",
    "nMLT = 24 # number of bins for MLT\n",
    "nMLAT = 10 # number of bins for MLAT\n",
    "\n",
    "# total bin rows in matrix slice (single time)\n",
    "nrows_total = nL*nMLT*nMLAT\n",
    "\n",
    "# (!)get non-location based predictors\n",
    "# base_values = design_matrix_tensor[-1].clone()\n",
    "\n",
    "base_values = design_matrix_tensor[0:len(swi_predictors),:].clone()\n",
    "\n",
    "# set up array\n",
    "# shape should be (nL*nMLT*nMLAT, number of predictors)\n",
    "dmatrix = np.zeros([nrows_total, len(predictors)])\n",
    "\n",
    "dm_indx = 0\n",
    "for i_L in range(0,nL):\n",
    "    for i_MLT in range(0,nMLT):\n",
    "        for i_MLAT in range(0,nMLAT):\n",
    "\n",
    "        # dmatrix[dm_indx, -3] = l_bins[i] # L\n",
    "        # dmatrix[dm_indx, -2] = mlt_bins[j] # MLT\n",
    "        # dmatrix[dm_indx, -1] = mlat_bins[k] # MLAT\n",
    "\n",
    "            # location predictors \n",
    "            dmatrix[dm_indx, -5] = i_L # L\n",
    "            dmatrix[dm_indx, -4] = np.cos(np.pi / 12 * i_MLT) # cos(MLT)\n",
    "            dmatrix[dm_indx, -3] = np.sin(np.pi / 12 * i_MLT) # sin(MLT)\n",
    "            dmatrix[dm_indx, -2] = np.cos(i_MLAT) # cos(MLAT)\n",
    "            dmatrix[dm_indx, -1] = np.sin(i_MLAT) # sin(MLAT)\n",
    "\n",
    "            dm_indx += 1 # raise deign matrix index\n",
    "\n",
    "\n",
    "# convert to torch tensor\n",
    "# [...]\n",
    "\n",
    "# test model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model(all_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [2, 2, 2, 2, 2],\n",
       "       [3, 3, 3, 3, 3],\n",
       "       [4, 4, 4, 4, 4],\n",
       "       [5, 5, 5, 5, 5],\n",
       "       [6, 6, 6, 6, 6],\n",
       "       [7, 7, 7, 7, 7],\n",
       "       [8, 8, 8, 8, 8],\n",
       "       [9, 9, 9, 9, 9]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.arange(10)\n",
    "np.repeat(x[:,np.newaxis], 5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 2. 3. 0.]\n",
      " [1. 2. 3. 0.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "b = np.zeros([2,4])\n",
    "print (a)\n",
    "print(b)\n",
    "\n",
    "b[:,0:3] = a[0,0:3]\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[168, 480]' is invalid for input of size 51240",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_locations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv-imef/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/venv-imef/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/unh-srl/imef/imef-statistics/proposal-model/prop_nn_models.py:85\u001b[0m, in \u001b[0;36mFeedForwardNN_MCDO.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m#  When modeling time series with feed-forward NN's, it's important to note that there's a neuron\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# for each time step AND FEATURE; so if you have 60 time steps and 2 features, then you have 120 numbers\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# to give as input; so the NN see the time steps and features *at the same time*\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# we can express this idea by taking our 3d array (with original shape [num_pts, seq_len, num_feats])\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# and unfold into 2d (with new shape [num_pts, seq_len * num_feats])\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    out = self.fc1(x)\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    out = self.relu(out)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    out = self.fc1(out)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    out = self.fc2(out)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[168, 480]' is invalid for input of size 51240"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for Izzak's code, see\n",
    "    - imef/data_manipulation.py\n",
    "    - visualizations/plot_nc_data.py\n",
    "    - imef/efield/model_creation/NN_functions.py\n",
    "    - imef/data/database.py\n",
    "        - **(predict_efield_and_potential function!)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "number_of_inputs = len(swi_predictors)  # number of inputs/predictors\n",
    "\n",
    "# unsure how to adjust this for all predicors? is this grabbing row or column?\n",
    "# izzak used:\n",
    "#   >> base_kp_values = design_matrix_tensor[-1].clone()\n",
    "# my variation (I don't know what to do for this):\n",
    "base_values = design_matrix_tensor[-1].clone()\n",
    "\n",
    "# izzak used:\n",
    "#   >> size_of_input_vector = 60 * number_of_inputs + 3\n",
    "# my variation:\n",
    "size_of_input_vector = 60 * number_of_inputs + 5\n",
    "\n",
    "# I THINK this is izzak's way of setting up the matrix to be accepted\n",
    "# by the model, but...its not clear.\n",
    "for L in range(4, 11):\n",
    "    for MLT in range(0, 24):\n",
    "        new_row = base_values.clone()\n",
    "        # new_row[:-3]\n",
    "        new_row[-3] = L\n",
    "        new_row[-2] = np.cos(np.pi / 12 * MLT)\n",
    "        new_row[-1] = np.sin(np.pi / 12 * MLT)\n",
    "        even_newer_row = torch.empty((1, size_of_input_vector))\n",
    "        even_newer_row[0] = new_row\n",
    "        if L == 4 and MLT == 0:\n",
    "            all_locations = even_newer_row\n",
    "        else:\n",
    "            all_locations = torch.cat((all_locations, even_newer_row))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(all_locations)\n",
    "\n",
    "# row1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (TBD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m base_values \u001b[38;5;241m=\u001b[39m design_matrix_tensor[\u001b[43mdesign_matrix_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "base_values = design_matrix_tensor[design_matrix_tensor.columns[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-imef",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
